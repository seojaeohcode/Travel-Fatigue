import requests
import pandas as pd
import numpy as np
from sklearn.cluster import KMeans
from sklearn.preprocessing import StandardScaler
import itertools
import time
import matplotlib.pyplot as plt
import seaborn as sns
from matplotlib import font_manager, rc

# --------------------------------------------------------------------------
# âœ… ì„¤ì • ë³€ìˆ˜
# --------------------------------------------------------------------------
# â—ï¸â—ï¸ ë³¸ì¸ì˜ ì¹´ì¹´ì˜¤ REST API í‚¤ë¥¼ ì…ë ¥í•˜ì„¸ìš”.
KAKAO_API_KEY = "6e5ff5f0fc34ba8dce84b422a33066bc"

# 1. í´ëŸ¬ìŠ¤í„°ë§ ë¶„ì„ ëŒ€ìƒì´ ë  ëŒ€í•œë¯¼êµ­ ëŒ€í‘œ ê´€ê´‘ ë„ì‹œ í›„ë³´êµ°
CANDIDATE_CITIES = [
    "ì„œìš¸ ì¢…ë¡œêµ¬", "ì„œìš¸ ì¤‘êµ¬", "ì„œìš¸ ê°•ë‚¨êµ¬", "ë¶€ì‚° í•´ìš´ëŒ€êµ¬", 
    "ë¶€ì‚° ì¤‘êµ¬", "ì œì£¼ì‹œ", "ì„œê·€í¬ì‹œ", "ê²½ì£¼ì‹œ", "ì „ì£¼ì‹œ ì™„ì‚°êµ¬", "ê°•ë¦‰ì‹œ"
]

# 2. ê° ë„ì‹œì˜ ë©´ì (kmÂ²) - (ì‚¬ì „ ì¡°ì‚¬ëœ ê³ ì •ê°’)
CITY_AREAS = {
    "ì„œìš¸ ì¢…ë¡œêµ¬": 23.91, "ì„œìš¸ ì¤‘êµ¬": 9.96, "ì„œìš¸ ê°•ë‚¨êµ¬": 39.5, "ë¶€ì‚° í•´ìš´ëŒ€êµ¬": 51.47,
    "ë¶€ì‚° ì¤‘êµ¬": 2.8, "ì œì£¼ì‹œ": 978.7, "ì„œê·€í¬ì‹œ": 870.8, "ê²½ì£¼ì‹œ": 1357.0,
    "ì „ì£¼ì‹œ ì™„ì‚°êµ¬": 95.2, "ê°•ë¦‰ì‹œ": 1040.0
}

# 3. ê´€ê´‘ íŠ¹ì„± ë¶„ì„ì„ ìœ„í•œ POI ì¹´í…Œê³ ë¦¬ (ì¹´ì¹´ì˜¤ë§µ API ê¸°ì¤€)
CATEGORY_CODES = {
    'attraction': 'AT4', # ê´€ê´‘ëª…ì†Œ
    'culture': 'CT1',    # ë¬¸í™”ì‹œì„¤
    'shopping': 'MT1',   # ì‡¼í•‘ (ëŒ€í˜•ë§ˆíŠ¸/ë°±í™”ì )
    'food': 'FD6',       # ìŒì‹ì 
}

# --------------------------------------------------------------------------
# í—¬í¼ í•¨ìˆ˜
# --------------------------------------------------------------------------
def get_total_poi_count(city, category_code):
    """íŠ¹ì • ë„ì‹œì™€ ì¹´í…Œê³ ë¦¬ì— ëŒ€í•œ ì „ì²´ POI ê°œìˆ˜ë¥¼ ë°˜í™˜í•©ë‹ˆë‹¤."""
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    params = {'query': city, 'category_group_code': category_code, 'size': 1}
    try:
        response = requests.get(url, headers=headers, params=params)
        if response.status_code == 200:
            return response.json()['meta']['total_count']
    except Exception:
        return 0
    return 0

def get_poi_coords(city, limit=20):
    """ë¶„ì‚°ë„ ê³„ì‚°ì„ ìœ„í•´ ë„ì‹œ ë‚´ ëŒ€í‘œ POIë“¤ì˜ ì¢Œí‘œë¥¼ ìˆ˜ì§‘í•©ë‹ˆë‹¤."""
    url = "https://dapi.kakao.com/v2/local/search/keyword.json"
    headers = {"Authorization": f"KakaoAK {KAKAO_API_KEY}"}
    coords = []
    
    # ì—¬ëŸ¬ ì¹´í…Œê³ ë¦¬ì˜ POIë¥¼ ìˆ˜ì§‘í•˜ì—¬ ë¶„ì‚°ë„ë¥¼ ê³„ì‚°
    categories = [CATEGORY_CODES['attraction'], CATEGORY_CODES['culture']]
    
    for category in categories:
        params = {
            'query': city, 
            'category_group_code': category, 
            'size': min(15, limit)  # ê° ì¹´í…Œê³ ë¦¬ë‹¹ ìµœëŒ€ 15ê°œ
        }
        try:
            response = requests.get(url, headers=headers, params=params)
            if response.status_code == 200:
                documents = response.json().get('documents', [])
                for doc in documents:
                    coords.append((float(doc['y']), float(doc['x']))) # (lat, lon)
        except Exception:
            continue
        
        time.sleep(0.1)  # API í˜¸ì¶œ ì œí•œ ë°©ì§€
    
    return coords

def calculate_dispersion(coords):
    """ì¢Œí‘œ ëª©ë¡ ê°„ì˜ í‰ê·  ê±°ë¦¬ë¥¼ ê³„ì‚°í•˜ì—¬ ë¶„ì‚°ë„ë¥¼ ì¸¡ì •í•©ë‹ˆë‹¤."""
    if len(coords) < 2: return 0
    total_dist = 0
    count = 0
    for p1, p2 in itertools.combinations(coords, 2):
        # Haversine formula to calculate distance between two lat/lon points
        R = 6371  # Radius of Earth in km
        lat1, lon1 = np.radians(p1)
        lat2, lon2 = np.radians(p2)
        dlon = lon2 - lon1
        dlat = lat2 - lat1
        a = np.sin(dlat / 2)**2 + np.cos(lat1) * np.cos(lat2) * np.sin(dlon / 2)**2
        c = 2 * np.arctan2(np.sqrt(a), np.sqrt(1 - a))
        distance = R * c
        total_dist += distance
        count += 1
    return total_dist / count if count > 0 else 0

# --------------------------------------------------------------------------
# ë©”ì¸ ì‹¤í–‰ ë¡œì§
# --------------------------------------------------------------------------
def run_city_clustering():
    print("--- [PRE-STEP] ê´€ê´‘ íŠ¹ì„± í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•œ ëŒ€í‘œ ì§€ì—­ ì„ ë°œ ì‹œì‘ ---")
    
    # 1. ê° í›„ë³´ ë„ì‹œë³„ 3ê°€ì§€ ì •ëŸ‰ ì§€í‘œ ê³„ì‚°
    city_features = []
    for city in CANDIDATE_CITIES:
        print(f"\n[{city}] ê´€ê´‘ íŠ¹ì„± ë¶„ì„ ì¤‘...")
        time.sleep(0.5)
        
        # ì§€í‘œ 1: ê´€ê´‘ìì› ë°€ì§‘ë„ (ê´€ê´‘ëª…ì†Œ+ë¬¸í™”ì‹œì„¤ ê°œìˆ˜ / ë©´ì )
        attraction_count = get_total_poi_count(city, CATEGORY_CODES['attraction'])
        culture_count = get_total_poi_count(city, CATEGORY_CODES['culture'])
        density = (attraction_count + culture_count) / CITY_AREAS[city]
        print(f"  - ë°€ì§‘ë„: {density:.2f} ê°œ/kmÂ²")

        # ì§€í‘œ 2: ê´€ê´‘ìì› ë‹¤ì–‘ì„± (ì—”íŠ¸ë¡œí”¼ ì§€ìˆ˜)
        category_counts = [get_total_poi_count(city, code) for code in CATEGORY_CODES.values()]
        total_pois = sum(category_counts)
        proportions = [count / total_pois for count in category_counts if count > 0]
        diversity = -sum(p * np.log2(p) for p in proportions if p > 0)
        print(f"  - ë‹¤ì–‘ì„±: {diversity:.2f}")

        # ì§€í‘œ 3: ê´€ê´‘ìì› ë¶„ì‚°ë„ (POI ê°„ í‰ê·  ê±°ë¦¬)
        coords = get_poi_coords(city)
        dispersion = calculate_dispersion(coords)
        print(f"  - ë¶„ì‚°ë„: {dispersion:.2f} km")
        
        city_features.append({
            'city': city,
            'density': density,
            'diversity': diversity,
            'dispersion': dispersion
        })

    df = pd.DataFrame(city_features)
    
    # 2. K-means í´ëŸ¬ìŠ¤í„°ë§ ì‹¤í–‰
    features = df[['density', 'diversity', 'dispersion']]
    scaler = StandardScaler()
    scaled_features = scaler.fit_transform(features)
    
    kmeans = KMeans(n_clusters=3, random_state=42, n_init=10)
    df['cluster'] = kmeans.fit_predict(scaled_features)
    
    # 3. ê° í´ëŸ¬ìŠ¤í„°ì˜ ëŒ€í‘œ ì§€ì—­ ì„ ë°œ
    print("\n" + "="*80)
    print("ğŸ“ í´ëŸ¬ìŠ¤í„°ë³„ ëŒ€í‘œ ë„ì‹œ ì„ ì • ê³¼ì •")
    print("="*80)
    
    centroids = kmeans.cluster_centers_
    representatives = []
    representative_info = []  # ëŒ€í‘œ ë„ì‹œ ì •ë³´ë¥¼ ì €ì¥
    
    for i in range(3):
        cluster_cities_df = df[df['cluster'] == i]
        cluster_data = scaled_features[df['cluster'] == i]
        centroid = centroids[i]
        
        # í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ê³„ì‚°
        avg_density = cluster_cities_df['density'].mean()
        avg_diversity = cluster_cities_df['diversity'].mean()
        avg_dispersion = cluster_cities_df['dispersion'].mean()
        
        print(f"\n[í´ëŸ¬ìŠ¤í„° {i+1}] ì†í•œ ë„ì‹œ: {', '.join(cluster_cities_df['city'].tolist())}")
        print(f"  í‰ê·  íŠ¹ì„± - ë°€ì§‘ë„: {avg_density:.2f}, ë‹¤ì–‘ì„±: {avg_diversity:.2f}, ë¶„ì‚°ë„: {avg_dispersion:.2f}km")
        
        # í´ëŸ¬ìŠ¤í„° ì¤‘ì‹¬ì—ì„œ ê° ë„ì‹œê¹Œì§€ì˜ ê±°ë¦¬ ê³„ì‚°
        distances = np.linalg.norm(cluster_data - centroid, axis=1)
        
        # ê°€ì¥ ê°€ê¹Œìš´ ë„ì‹œ ì°¾ê¸°
        closest_point_index = np.argmin(distances)
        representative_city_index = df[df['cluster'] == i].index[closest_point_index]
        rep_city = df.loc[representative_city_index]['city']
        
        representatives.append(rep_city)
        representative_info.append({
            'cluster': i,
            'city': rep_city,
            'distance': distances[closest_point_index],
            'avg_density': avg_density,
            'avg_dispersion': avg_dispersion
        })
        
        print(f"  âœ… ëŒ€í‘œ ë„ì‹œ: {rep_city} (ì¤‘ì‹¬ì ê³¼ì˜ ê±°ë¦¬: {distances[closest_point_index]:.4f})")

    # 4. ìµœì¢… ê²°ê³¼ ì¶œë ¥ ë° ì‹œê°í™”
    # í•œê¸€ í°íŠ¸ ì„¤ì •
    try:
        # Windows ê¸°ì¤€ 'ë§‘ì€ ê³ ë”•'
        path = "c:/Windows/Fonts/malgun.ttf"
        font_name = font_manager.FontProperties(fname=path).get_name()
        rc('font', family=font_name)
    except:
        # Mac OS ê¸°ì¤€ 'AppleGothic'
        try:
            rc('font', family='AppleGothic')
        except:
            print("í•œê¸€ í°íŠ¸ë¥¼ ì°¾ì„ ìˆ˜ ì—†ì–´ ì¼ë¶€ ê¸€ìê°€ ê¹¨ì§ˆ ìˆ˜ ìˆìŠµë‹ˆë‹¤.")

    plt.figure(figsize=(14, 9))
    
    # ëŒ€í‘œ ë„ì‹œì™€ ì¼ë°˜ ë„ì‹œ ë¶„ë¦¬
    df['is_representative'] = df['city'].isin(representatives)
    
    # ì¼ë°˜ ë„ì‹œ ë¨¼ì € ê·¸ë¦¬ê¸°
    non_rep = df[~df['is_representative']]
    scatter_plot = sns.scatterplot(
        data=non_rep, x='dispersion', y='density', hue='cluster', s=200, 
        palette='viridis', alpha=0.5, legend=False
    )
    
    # ëŒ€í‘œ ë„ì‹œëŠ” í¬ê³  ì§„í•˜ê²Œ
    rep_cities = df[df['is_representative']]
    sns.scatterplot(
        data=rep_cities, x='dispersion', y='density', hue='cluster', s=500, 
        palette='viridis', alpha=1.0, edgecolor='red', linewidth=3, legend='full'
    )
    
    plt.title('ëŒ€í•œë¯¼êµ­ ì£¼ìš” ê´€ê´‘ ë„ì‹œ í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ (ë¹¨ê°„ í…Œë‘ë¦¬ = ëŒ€í‘œ ë„ì‹œ)', fontsize=18, pad=20)
    plt.xlabel('ê´€ê´‘ìì› ë¶„ì‚°ë„ (POI ê°„ í‰ê·  ê±°ë¦¬, km)  â†’  (ë„“ê²Œ í¼ì ¸ìˆìŒ)', fontsize=13)
    plt.ylabel('ê´€ê´‘ìì› ë°€ì§‘ë„ (POI ê°œìˆ˜ / ë©´ì )  â†’  (ë¹½ë¹½í•˜ê²Œ ëª¨ì—¬ìˆìŒ)', fontsize=13)
    
    # ê° ì  ì˜†ì— ë„ì‹œ ì´ë¦„ í‘œì‹œ (ëŒ€í‘œ ë„ì‹œëŠ” êµµê²Œ)
    for i, point in df.iterrows():
        if point['is_representative']:
            plt.text(point['dispersion'] + 0.5, point['density'], str(point['city']), 
                    fontsize=12, fontweight='bold', color='red')
        else:
            plt.text(point['dispersion'] + 0.5, point['density'], str(point['city']), 
                    fontsize=10, alpha=0.7)
        
    plt.legend(title='í´ëŸ¬ìŠ¤í„° ìœ í˜•', bbox_to_anchor=(1.02, 1), loc='upper left')
    plt.grid(True, linestyle='--', alpha=0.6)
    plt.tight_layout(rect=[0, 0, 0.85, 1]) # ë²”ë¡€ ê³µê°„ í™•ë³´
    
    # ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥
    plt.savefig("city_clustering_result.png", dpi=300)
    print("\n\nâœ… í´ëŸ¬ìŠ¤í„°ë§ ê²°ê³¼ê°€ 'city_clustering_result.png' ì´ë¯¸ì§€ íŒŒì¼ë¡œ ì €ì¥ë˜ì—ˆìŠµë‹ˆë‹¤.")
    plt.show()

    print("\n\n" + "="*80)
    print("ğŸ‰ [ìµœì¢… ì„ ì •] ëŒ€í•œë¯¼êµ­ ê´€ê´‘ì§€ ë‹¤ì–‘ì„±ì„ ëŒ€í‘œí•˜ëŠ” 3ê°œ ì§€ì—­ ğŸ‰")
    print("="*80)
    
    # í´ëŸ¬ìŠ¤í„° íŠ¹ì„± ì„¤ëª…
    cluster_types = {
        'high_density': None,    # ë†’ì€ ë°€ì§‘ë„
        'medium': None,          # ì¤‘ê°„ íŠ¹ì„±
        'low_density_high_dispersion': None  # ë‚®ì€ ë°€ì§‘ë„, ë†’ì€ ë¶„ì‚°ë„
    }
    
    for info in representative_info:
        if info['avg_density'] > 20:
            cluster_types['high_density'] = info
        elif info['avg_dispersion'] > 10:
            cluster_types['low_density_high_dispersion'] = info
        else:
            cluster_types['medium'] = info
    
    rank = 1
    for type_name, info in cluster_types.items():
        if info is None:
            continue
        city_data = df[df['city'] == info['city']].iloc[0]
        cluster_cities = df[df['cluster'] == info['cluster']]['city'].tolist()
        
        # ìœ í˜• ì„¤ëª…
        if type_name == 'high_density':
            type_desc = "ë„ì‹¬ ë°€ì§‘í˜• (ê´€ê´‘ìì›ì´ ì¢ì€ ì§€ì—­ì— ì§‘ì¤‘)"
        elif type_name == 'low_density_high_dispersion':
            type_desc = "ê´‘ì—­ ë¶„ì‚°í˜• (ê´€ê´‘ìì›ì´ ë„“ì€ ì§€ì—­ì— ë¶„í¬)"
        else:
            type_desc = "ì¤‘ê°„ ê· í˜•í˜• (ë°€ì§‘ë„ì™€ ë¶„ì‚°ë„ê°€ ê· í˜•)"
        
        print(f"\n[{rank}] â­ {info['city']} â­")
        print(f"  ìœ í˜•: {type_desc}")
        print(f"  í´ëŸ¬ìŠ¤í„°: {info['cluster']+1}ë²ˆ (ê°™ì€ ìœ í˜•: {', '.join(cluster_cities)})")
        print(f"  ê´€ê´‘ íŠ¹ì„±:")
        print(f"    - ë°€ì§‘ë„: {city_data['density']:.2f} ê°œ/kmÂ²")
        print(f"    - ë‹¤ì–‘ì„±: {city_data['diversity']:.2f}")
        print(f"    - ë¶„ì‚°ë„: {city_data['dispersion']:.2f} km")
        rank += 1

    print("\n" + "="*80)
    print("ğŸ“Œ ìµœì¢… ì„ ì •ëœ 3ê°œ ëŒ€í‘œ ì§€ì—­: " + " / ".join([f"â­{city}â­" for city in representatives]))
    print("="*80)
    
    print("\n[ê²°ë¡ ]")
    print("ìœ„ 3ê°œ ì§€ì—­ì€ K-means í´ëŸ¬ìŠ¤í„°ë§ì„ í†µí•´ ë„ì¶œëœ ì„œë¡œ ë‹¤ë¥¸ ê´€ê´‘ íŠ¹ì„±ì„ ê°€ì§„")
    print("ìœ í˜•ë³„ ëŒ€í‘œ ë„ì‹œë¡œ, ëŒ€í•œë¯¼êµ­ ê´€ê´‘ì§€ì˜ ë‹¤ì–‘ì„±ì„ ê°ê´€ì ìœ¼ë¡œ ëŒ€í‘œí•©ë‹ˆë‹¤.")
    print("ë³¸ ë¶„ì„ì˜ ë¹„êµ ëŒ€ìƒ ì„ ì •ì´ ì„ì˜ì ì´ì§€ ì•ŠìŒì„ ë°ì´í„°ë¡œ ì¦ëª…í•©ë‹ˆë‹¤.")

if __name__ == "__main__":
    run_city_clustering()
